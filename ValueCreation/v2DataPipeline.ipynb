{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T23:51:17.161973Z",
     "start_time": "2025-10-02T23:51:15.466089Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ----- Read Excel file ----- #\n",
    "REL_PATH = Path(\"InputData/CoreData.xlsx\")\n",
    "\n",
    "def find_upwards(rel_path: Path, max_up: int = 8) -> Path:\n",
    "    \"\"\"\n",
    "    Starting at cwd, walk up to `max_up` parents to find `rel_path`.\n",
    "    Returns the resolved path if found; raises FileNotFoundError otherwise.\n",
    "    \"\"\"\n",
    "    here = Path.cwd()\n",
    "    for parent in [here, *here.parents][: max_up + 1]:\n",
    "        candidate = (parent / rel_path)\n",
    "        if candidate.exists():\n",
    "            return candidate.resolve()\n",
    "    # Helpful diagnostics\n",
    "    raise FileNotFoundError(\n",
    "        f\"Couldn't locate '{rel_path.as_posix()}' from {here} by walking up {max_up} levels.\\n\"\n",
    "        f\"- Current working directory: {here}\\n\"\n",
    "        f\"- Checked: {[str((p / rel_path)) for p in [here, *here.parents][: max_up + 1]]}\"\n",
    "    )\n",
    "\n",
    "INPUT_XLSX = find_upwards(REL_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "xfile = pd.ExcelFile(INPUT_XLSX)\n",
    "sheets = xfile.sheet_names\n",
    "print(\"Resolved path:\", INPUT_XLSX)\n",
    "print(\"Sheets:\", sheets)\n",
    "\n",
    "assert isinstance(sheets, list), \"Expected a list\"\n",
    "assert sheets and all(isinstance(s, str) and s.strip() for s in sheets), \"Sheet names must be non-empty strings\"\n",
    "assert len(sheets) == len(set(sheets)), \"Duplicate sheet names detected\"\n",
    "print(\"Check 1 passed.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved path: /Users/michael/Library/Mobile Documents/com~apple~CloudDocs/Studium TUM/Master Management and Technology/06 Master Thesis/00 Thesis/05Code/InputData/CoreData.xlsx\n",
      "Sheets: ['Metadata', 'dashboard', 'general_partner', 'fund', 'fund_cash_flow', 'capital_account', 'deal', 'deal_time_series', 'deal_cash_flow', 'deal_partner', 'deal_acquirer', 'deal_vendor', 'organization', 'person']\n",
      "Check 1 passed.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T23:51:19.543599Z",
     "start_time": "2025-10-02T23:51:17.193917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "SHEET = \"deal_time_series\"\n",
    "\n",
    "# Guard: make sure the sheet exists (uses `sheets` from Step 1)\n",
    "assert SHEET in sheets, f\"'{SHEET}' not found. Available sheets: {sheets}\"\n",
    "\n",
    "# Read with first row as header\n",
    "dts = pd.read_excel(INPUT_XLSX, sheet_name=SHEET, header=0)\n",
    "\n",
    "# Display column names and first 10 data rows (i.e., Excel rows 2â€“11)\n",
    "print(\"Column names:\", list(dts.columns))\n",
    "display(dts.head(5))\n",
    "\n",
    "# --- Check 2\n",
    "assert isinstance(dts, pd.DataFrame), \"Expected a pandas DataFrame.\"\n",
    "assert not dts.empty, \"Sheet loaded but contains no data.\"\n",
    "assert all(isinstance(c, str) and c.strip() for c in dts.columns), \"Invalid/empty column names.\"\n",
    "print(f\"Check 2 passed. Shape: {dts.shape}. Showing 5 data rows above.\")\n"
   ],
   "id": "858ab65c4fbda592",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['id', 'total_value', 'ebitda', 'reference_period_type_suffix', 'moic_gross', 'data_room_id', 'created_by_user_id', 'recurring_revenue', 'bridge_financing', 'reporting_currency_financials', 'irr_net', 'reference_period_type_prefix', 'moic_net', 'data_room_name', 'realized_value', 'irr_gross', 'ebitda_adjusted', 'net_debt', 'ebitda_multiple', 'enterprise_value_valuation_rationale', 'is_main', 'equity', 'reporting_currency_valuation', 'management_equity_percentage', 'revenue_multiple', 'recurring_revenue_percentage', 'quarterly_company_update', '_created_at_utc', 'enterprise_value', 'enterprise_value_valuation_multiple', '_year', 'reference_date', 'irr_net_unlevered', 'capex', 'total_investment_cost', 'deal_revision_id', 'reported_date', 'deal_id', 'unrealized_value', 'predicted_sentiment', 'ebit', 'ebitda_adjusted_note', 'ebitda_margin', 'cumulative_addons', 'moic_net_unlevered', 'revenue', 'fund_equity_invested', '_quarter', '_revision_id', 'ownership_economic_percentage', 'enterprise_value_valuation_amount']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                     id  total_value      ebitda  \\\n",
       "0  b0cd7032-72f6-46d0-ae21-7a0ca81297eb          NaN         NaN   \n",
       "1  997bb98e-9ab1-47be-b04b-767d225f60a9          NaN   7600000.0   \n",
       "2  1eab0e13-6d1d-4c99-a8a0-6c32b56de012          NaN  34000000.0   \n",
       "3  9ae2e65b-ec9d-4215-8982-f39658e9fa1e   19839000.0  13747260.0   \n",
       "4  fa677592-875d-413e-91fe-c8af1dd99f63   40736000.0  18894000.0   \n",
       "\n",
       "  reference_period_type_suffix  moic_gross  \\\n",
       "0                       Actual         NaN   \n",
       "1                       Actual         NaN   \n",
       "2                       Actual         NaN   \n",
       "3                          NaN         NaN   \n",
       "4                          NaN         NaN   \n",
       "\n",
       "                           data_room_id                    created_by_user_id  \\\n",
       "0  203ffba5-3ebb-454a-844c-87cee656bd95  25bd1583-7869-465c-9dc4-664685cd3a6c   \n",
       "1  d40592d4-9127-4e77-a8c7-9da4755a6105  25bd1583-7869-465c-9dc4-664685cd3a6c   \n",
       "2  d40592d4-9127-4e77-a8c7-9da4755a6105  25bd1583-7869-465c-9dc4-664685cd3a6c   \n",
       "3  9d92005d-7097-4949-88ea-8eb6ff688a86  38ed8bb8-d707-4652-94c0-6a094d116b50   \n",
       "4  9d92005d-7097-4949-88ea-8eb6ff688a86  38ed8bb8-d707-4652-94c0-6a094d116b50   \n",
       "\n",
       "   recurring_revenue  bridge_financing reporting_currency_financials  ...  \\\n",
       "0                NaN               NaN                           USD  ...   \n",
       "1                NaN               NaN                           EUR  ...   \n",
       "2                NaN               NaN                           EUR  ...   \n",
       "3                NaN               NaN                           EUR  ...   \n",
       "4                NaN               NaN                           EUR  ...   \n",
       "\n",
       "   ebitda_adjusted_note ebitda_margin  cumulative_addons moic_net_unlevered  \\\n",
       "0                   NaN           NaN                NaN                NaN   \n",
       "1                   NaN         0.046                NaN                NaN   \n",
       "2                   NaN         0.121                NaN                NaN   \n",
       "3                   NaN           NaN                NaN                NaN   \n",
       "4                   NaN           NaN                NaN                NaN   \n",
       "\n",
       "       revenue  fund_equity_invested  _quarter  \\\n",
       "0          NaN                   NaN         1   \n",
       "1  164000000.0                   NaN         1   \n",
       "2  280000000.0                   NaN         2   \n",
       "3   48663900.0            19839000.0         3   \n",
       "4  393249800.0            40736000.0         2   \n",
       "\n",
       "                           _revision_id  ownership_economic_percentage  \\\n",
       "0  cccb3423-eb71-452a-92f1-3b4a64100646                            NaN   \n",
       "1  64ef422a-f3cc-44fe-bf2b-fe5955950008                            NaN   \n",
       "2  3e0b9962-f308-420f-9c62-5fa24f5b2e7e                            NaN   \n",
       "3  9ae2e65b-ec9d-4215-8982-f39658e9fa1e                            1.0   \n",
       "4  fa677592-875d-413e-91fe-c8af1dd99f63                            0.5   \n",
       "\n",
       "  enterprise_value_valuation_amount  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 51 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total_value</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>reference_period_type_suffix</th>\n",
       "      <th>moic_gross</th>\n",
       "      <th>data_room_id</th>\n",
       "      <th>created_by_user_id</th>\n",
       "      <th>recurring_revenue</th>\n",
       "      <th>bridge_financing</th>\n",
       "      <th>reporting_currency_financials</th>\n",
       "      <th>...</th>\n",
       "      <th>ebitda_adjusted_note</th>\n",
       "      <th>ebitda_margin</th>\n",
       "      <th>cumulative_addons</th>\n",
       "      <th>moic_net_unlevered</th>\n",
       "      <th>revenue</th>\n",
       "      <th>fund_equity_invested</th>\n",
       "      <th>_quarter</th>\n",
       "      <th>_revision_id</th>\n",
       "      <th>ownership_economic_percentage</th>\n",
       "      <th>enterprise_value_valuation_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b0cd7032-72f6-46d0-ae21-7a0ca81297eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Actual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203ffba5-3ebb-454a-844c-87cee656bd95</td>\n",
       "      <td>25bd1583-7869-465c-9dc4-664685cd3a6c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>cccb3423-eb71-452a-92f1-3b4a64100646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>997bb98e-9ab1-47be-b04b-767d225f60a9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7600000.0</td>\n",
       "      <td>Actual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d40592d4-9127-4e77-a8c7-9da4755a6105</td>\n",
       "      <td>25bd1583-7869-465c-9dc4-664685cd3a6c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>64ef422a-f3cc-44fe-bf2b-fe5955950008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1eab0e13-6d1d-4c99-a8a0-6c32b56de012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34000000.0</td>\n",
       "      <td>Actual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d40592d4-9127-4e77-a8c7-9da4755a6105</td>\n",
       "      <td>25bd1583-7869-465c-9dc4-664685cd3a6c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3e0b9962-f308-420f-9c62-5fa24f5b2e7e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9ae2e65b-ec9d-4215-8982-f39658e9fa1e</td>\n",
       "      <td>19839000.0</td>\n",
       "      <td>13747260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9d92005d-7097-4949-88ea-8eb6ff688a86</td>\n",
       "      <td>38ed8bb8-d707-4652-94c0-6a094d116b50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48663900.0</td>\n",
       "      <td>19839000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9ae2e65b-ec9d-4215-8982-f39658e9fa1e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fa677592-875d-413e-91fe-c8af1dd99f63</td>\n",
       "      <td>40736000.0</td>\n",
       "      <td>18894000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9d92005d-7097-4949-88ea-8eb6ff688a86</td>\n",
       "      <td>38ed8bb8-d707-4652-94c0-6a094d116b50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393249800.0</td>\n",
       "      <td>40736000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>fa677592-875d-413e-91fe-c8af1dd99f63</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 2 passed. Shape: (4956, 51). Showing 5 data rows above.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T23:51:22.388036Z",
     "start_time": "2025-10-02T23:51:19.593780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Config\n",
    "SHEET = \"deal_time_series\"\n",
    "TARGET_DIR = (find_upwards(Path(\"ValueCreation\")) / \"Data\")\n",
    "TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TARGET_CSV = TARGET_DIR / \"working.csv\"\n",
    "\n",
    "assert SHEET in sheets, f\"Sheet '{SHEET}' not found.\"\n",
    "\n",
    "# Load only the key column; no filtering, no sorting\n",
    "usecols = [\"id\"]\n",
    "raw = pd.read_excel(INPUT_XLSX, sheet_name=SHEET, usecols=usecols)\n",
    "\n",
    "# Preserve order exactly as in the sheet\n",
    "df = raw[[\"id\"]]\n",
    "\n",
    "# Persist\n",
    "df.to_csv(TARGET_CSV, index=False)\n",
    "print(f\"Wrote {len(df):,} rows to {TARGET_CSV}\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "assert TARGET_CSV.exists(), f\"Missing output: {TARGET_CSV}\"\n",
    "check_df = pd.read_csv(TARGET_CSV)\n",
    "\n",
    "# 1) Columns exactly as specified and in order\n",
    "assert list(check_df.columns) == [\"id\"], list(check_df.columns)\n",
    "\n",
    "# 2) Row count preserved\n",
    "assert len(check_df) == len(raw), f\"Row count changed: raw={len(raw)} vs written={len(check_df)}\"\n",
    "\n",
    "# 3) Order preserved: id sequence identical pre/post write\n",
    "assert check_df[\"id\"].tolist() == raw[\"id\"].tolist(), \"Row order changed.\"\n",
    "\n",
    "# 4) Key integrity: non-null and unique\n",
    "assert check_df[\"id\"].notna().all(), \"Null id found.\"\n",
    "assert not check_df[\"id\"].duplicated().any(), \"Duplicate id values found.\"\n",
    "\n",
    "print(\"INIT check passed. Shape:\", check_df.shape)\n"
   ],
   "id": "f61dcef70e669d4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 4,956 rows to /Users/michael/Library/Mobile Documents/com~apple~CloudDocs/Studium TUM/Master Management and Technology/06 Master Thesis/00 Thesis/05Code/ValueCreation/Data/working.csv\n",
      "INIT check passed. Shape: (4956, 1)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T23:51:24.867686Z",
     "start_time": "2025-10-02T23:51:22.413579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Config\n",
    "SHEET = \"deal_time_series\"\n",
    "TARGET_CSV = (find_upwards(Path(\"ValueCreation\")) / \"Data\" / \"working.csv\")\n",
    "\n",
    "# --- Load current working file and the source sheet\n",
    "working = pd.read_csv(TARGET_CSV, dtype={\"id\": str})\n",
    "\n",
    "requested = [\n",
    "    \"deal_id\", \"reference_date\", \"enterprise_value\", \"net_debt\", \"equity\",\n",
    "    \"revenue\", \"ebitda\", \"ownership_economic_percentage\", \"data_room_name\"\n",
    "]\n",
    "src = pd.read_excel(INPUT_XLSX, sheet_name=SHEET, usecols=[\"id\", *requested], dtype={\"id\": str})\n",
    "\n",
    "# Parse Excel-serial 'reference_date' to ISO yyyy-mm-dd (CSV-friendly)\n",
    "if \"reference_date\" in src.columns:\n",
    "    s = src[\"reference_date\"]\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        dt = pd.to_datetime(s, unit=\"D\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "    else:\n",
    "        dt = pd.to_datetime(s, errors=\"coerce\")\n",
    "    src[\"reference_date\"] = dt.dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Only add columns that aren't already present\n",
    "to_add = [c for c in requested if c not in working.columns]\n",
    "src = src[[\"id\", *to_add]]\n",
    "\n",
    "# Preserve original row order\n",
    "working[\"_ord\"] = np.arange(len(working))\n",
    "\n",
    "# Left-join on string id\n",
    "out = working.merge(src, on=\"id\", how=\"left\")\n",
    "\n",
    "# Restore order and drop helper\n",
    "out = out.sort_values(\"_ord\").drop(columns=\"_ord\")\n",
    "\n",
    "# Save\n",
    "out.to_csv(TARGET_CSV, index=False)\n",
    "print(f\"Added columns: {to_add}. Wrote {len(out):,} rows to {TARGET_CSV}.\")\n"
   ],
   "id": "33d57f70b1226003",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added columns: ['deal_id', 'reference_date', 'enterprise_value', 'net_debt', 'equity', 'revenue', 'ebitda', 'ownership_economic_percentage', 'data_room_name']. Wrote 4,956 rows to /Users/michael/Library/Mobile Documents/com~apple~CloudDocs/Studium TUM/Master Management and Technology/06 Master Thesis/00 Thesis/05Code/ValueCreation/Data/working.csv.\n",
      "ADD_COLUMNS check passed. Shape: (4956, 10)\n"
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
